# EX-02-Cross-Platform-Prompting-Evaluating-Diverse-Techniques-in-AI-Powered-Text-Summarization

## AIM
To evaluate and compare the effectiveness of prompting techniques (zero-shot, few-shot, chain-of-thought, role-based) across different AI platforms (e.g., ChatGPT, Gemini, Claude, Copilot) in a specific task: text summarization.

## Scenario:
You are part of a content curation team for an educational platform that delivers quick summaries of research papers to undergraduate students. Your task is to summarize a 500-word technical article on "The Basics of Blockchain Technology" using multiple AI platforms and prompting strategies.

Your goal is to determine which combination of prompting technique + platform provides the best summary in terms of:
Comparative Analysis of Language Model Responses to Broad vs. Refined Prompts
1. Introduction
This report evaluates how different AI language models respond to broad/unstructured prompts versus refined prompts. The comparison focuses on the quality, accuracy, and depth of responses across different scenarios.
2. Models Tested
•
GPT-4 (Advanced proprietary model)
•
Claude (Anthropic's AI assistant)
•
Gemini (Google's AI)
•
Llama 3 (Open-source model)
3. Test Scenarios and Results
Scenario 1: General Knowledge
Broad Prompt: "Tell me about AI."
Key Findings
1.
Broad Prompts vs. Refined Prompts:
o
GPT-4 and Claude adapt well to both, but provide significantly deeper insights when given a structured prompt.
o
Gemini and Llama 3 perform better when given refined prompts, struggling with depth on broad queries.
2.
Accuracy:
o
All models were generally accurate, but open-source models like Llama 3 sometimes provided less precise answers in unstructured queries.
3.
Depth of Response:
o
GPT-4 consistently delivered the deepest responses, especially with refined prompts.
o
Claude performed well in logical reasoning and creativity.
o
Gemini struggled slightly with depth but performed adequately.
o
Llama 3 required very specific prompting for best results.

## Result
For general use cases, GPT-4 and Claude are the best choices, with GPT-4 leading in technical and deep knowledge.
•
For more structured and technical explanations, Claude and Gemini can perform well if given clear instructions.
•
For open-source alternatives, Llama 3 works decently but struggles without explicit prompting.

